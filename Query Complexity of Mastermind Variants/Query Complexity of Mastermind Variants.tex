% Christopher was here
% Author and Title Information
\newcommand*{\thetitle}{Query Complexity of Mastermind Variants}
\newcommand*{\theauthor}{Aaron Berger\quad Christopher Chute\quad Matthew Stone}
\newcommand*{\duedate}{January 28, 2016}

% Document Settings
\documentclass[12pt, a4paper]{article}
\author{\theauthor}
\title{\thetitle}
\date{\duedate}
\usepackage[top=.75in, left=0.5in, right=0.5in, bottom=1.5in]{geometry}
\usepackage{amsmath, amsthm, amssymb}
\newtheorem{lem}{Lemma}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage[T1]{fontenc}
\usepackage{titling}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[nottoc]{tocbibind}

\setlength{\droptitle}{-4em}
\posttitle{\par\end{center}\vspace{-.35em}}

% Header Formatting
%\usepackage{fancyhdr}
%\setlength{\headheight}{48pt}
%\pagestyle{fancyplain}
%\lhead{\thetitle}
%\rhead{\theauthor\\\duedate}
%\rfoot{}
%\cfoot{\thepage}

% Math Macros
\newcommand{\R}{\mathbb{R}}           % Real numbers
\newcommand{\Z}{\mathbb{Z}}           % Integer numbers
\newcommand{\Q}{\mathbb{Q}}           % Rational numbers
\newcommand{\N}{\mathbb{N}}           % Natural numbers
\newcommand{\C}{\mathbb{C}}           % Complex numbers
\newcommand{\F}{\mathbb{F}}           % Field (e.g, Z mod pZ)
\newcommand*{\bigbar}{\overline}      % Overline
\newcommand*{\ihat}{\hat{\imath}}     % i-hat
\newcommand*{\jhat}{\hat{\jmath}}     % j-hat
\newcommand{\lcm}{\text{l.c.m.}}      % Least common multiple
\newcommand{\union}{\cup}             % Set union
\newcommand{\intersect}{\cap}         % Set intersection
\newcommand{\im}{\text{im}}           % Image of a function
\newcommand{\vphi}{\varphi}           % Attractive phi
\newcommand{\normal}{\trianglelefteq} % Is a normal subgroup of
\newcommand{\abel}{^{\text{ab}}}      % Abelianization
\newcommand{\Aut}{\text{Aut}}         % Automorphisms
\newcommand{\Hol}{\text{Hol}}         % Holomorph
\newcommand{\inv}{^{-1}}              % Inverse
\newcommand{\nth}{^{\text{th}}}       % Superscript n-th
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\begin{document}
\maketitle
\begin{abstract}
	We study variants of Mastermind, a popular board game in which the objective is sequence reconstruction. In this two-player game, the so-called \textit{codemaker} constructs a hidden sequence $H = (h_1, h_2, \ldots, h_n)$ of colors selected from an alphabet $\mathcal{A} = \{1,2,\ldots, k\}$ (\textit{i.e.,} $h_i\in\mathcal{A}$ for all $i\in\{1,2,\ldots, n\}$). The game then proceeds in turns, each of which consists of two parts: in turn $t$, the second player (the \textit{codebreaker}) first submits a query sequence $Q_t = (q_1, q_2, \ldots, q_n)$ with $q_i\in \mathcal{A}$ for all $i$, and second receives feedback $\Delta(Q_t, H)$, where $\Delta$ is some agreed-upon function of distance between two sequences with $n$ components. The game terminates when $Q_t = H$, and the codebreaker seeks to end the game in as few turns as possible. Throughout we let $f(n,k)$ denote the smallest integer such that the codebreaker can determine any $H$ in $f(n,k)$ turns. We prove three main results: First, when $H$ is known to be a permutation of $\{1,2,\ldots, n\}$, we prove that $f(n, n)\ge n - \log\log(n)$ for all sufficiently large $n$. Second, we show that Knuth's Minimax algorithm identifies any $H$ in at most $nk$ queries. Third, when feedback is not received until all queries have been submitted, we show that $f(n,k)=\Omega(n\log k)$.
\end{abstract}

\section{Introduction}
Mastermind is a game created by Mordechai Meirowitz in 1970. In the original game, the codebreaker's objective is to guess a hidden sequence of 4 colors, each chosen from a pool of 6. Knuth analyzed the original game in 1977, and showed that there exists a strategy that guarantees guessing the hidden vector in no more than 5 turns \cite{DK76}. Mastermind is a two-player games centered around reconstruction of a hidden sequence. In all variants of the game, one player is given the role of \textit{codemaker}, and the other is denoted the \textit{codebreaker}. The codemaker begins the game by constructing a hidden sequence $H = (h_1, h_2, \ldots, h_n)$ where each component is selected from an alphabet $\mathcal{A} = \{1,2,\ldots,k\}$ of $k$ colors (that is, $h_i\in\mathcal{A}$ for all $i\in\{1,2,\ldots,n\}$). The goal of the codebreaker is to uniquely determine the hidden sequence $H$ through a series of queries, which are submissions of vectors of the form $Q_t = (q_1, q_2, \ldots, q_n)$. The codebreaker always seeks to determine $H$ with as few queries as possible, however the nature of these queries, the feedback received after a query, and the restrictions on $H$ differ between variants. Erd\H{o}s and R\'enyi, for example, studied a 2-color version of the game, before Mastermind existed, in \cite{ER63}.

The variants of Mastermind which we study are defined by settings of the tuple $(n, k, \Delta, R, A)$. These parameters are defined as follows:
\begin{enumerate}[label=(\roman*)]
	\item ($n$) \textit{Length of Sequence.} The parameter $n$ denotes the length of the hidden sequence $H$ created by the codemaker, hence $H = (h_1, h_2, \ldots, h_n)$. The codebreaker is also required to submit query vectors of length $n$, so the $t\nth$ query vector takes the form $Q_t = (q_1, q_2, \ldots, q_n)$.
	
	\item ($k$) \textit{Size of Alphabet.} This parameter determines the number of possible values for components of $H$ and $Q_t$. Associated with each game is an alphabet $\mathcal{A} = \{1,2,\ldots,k\}$ from which the components of $H$ and $Q_t$ are selected. That is, $h_i\in\{1,2,\ldots,k\}$ and $q_i\in\{1,2,\ldots,k\}$.
	
	\item($\Delta$) \textit{Distance Function.} Each variant of Mastermind has an associated distance function $\Delta$, giving the distance between two sequences of length $n$. For each query sequence $Q_t = (q_1, q_2, \ldots, q_n)$ submitted by the codebreaker, the codemaker gives feedback $\Delta(Q_t, H)$. The information yielded by $\Delta(Q_t, H)$ clearly influences the number of queries needed to identify the hidden vector $H$. For example, if $\Delta$ is defined by $\Delta(Q_t, H) = H$ then trivially the codebreaker can determine $H$ in one query. If $\Delta(Q_t, H) = 0$, then all sequences of length $n$ must be queried to guarantee a win. We study the following distance functions:
	\begin{enumerate}[label=\alph*.]
		\item\textit{``Black-peg and white-peg.''} Informally, a black peg denotes ``the correct color in the correct spot,'' and a white peg denotes ``the correct color in an incorrect spot.'' Formally, let $Q_t$ and $H$ be as above. The black-peg and white-peg distance function is defined by $\Delta(Q_t, H) = (b(Q_t, H), w(Q_t, H))$ where
		\begin{equation}\label{blackHitsDefinition}
			b(Q_t, H) = \left|\{i\in [1,n] \mid q_i = h_i\}\right|,
		\end{equation}
		and
		\begin{equation*}\label{whiteHitsDefinition}
			w(Q_t, H) = \max_{\sigma}~b(\sigma(Q_t), H) - b(Q_t, H),
		\end{equation*}
		where $\sigma$ iterates over all permutations of $Q_t$. We note that this is the distance function used in the original game of Mastermind.

		\item\textit{``Black-peg-only.''} When $\Delta$ is the black-peg-only distance function, it is defined by $\Delta(Q_t, H) = b(Q_t, H)$, where $b$ is defined as in equation (\ref{blackHitsDefinition}).
	\end{enumerate}
	We will denote the black-peg-only distance function by $\Delta = b$, and the black-white distance function by $\Delta = bw$.
	
	\item($R$) \textit{Repetition.} The parameter $R$ is a Boolean restriction on the components of $H$. If $R$ is true, we say that the variant game is \textit{with repeats} or that repeats are allowed. In this case, the hidden vector $H$ may have repeated colors, that is, we allow $h_i = h_j$ for any $i,j\in\{1,2,\ldots, n\}$. When $R$ is false, we say that the variant is \textit{no repeats}, and we require $h_i\neq h_j$ when $i\neq j$, and so we necessarily require $k \geq n$. In particular, when $R$ is false and $k = n$, we have that $H$ must be a permutation of $\{1, 2, \ldots, n\}$, and we refer to this variant as the \textit{Permutation Game.}
	
	\item($A$) \textit{Adaptiveness.} The Boolean parameter $A$ determines whether the codebreaker receives feedback after each query. If $A$ is true, we say that the game is \textit{adaptive}. In this case the game consists of two-part turns: on the $t\nth$ turn, the codebreaker first submits a query sequence $Q_t$, and then receives feedback $\Delta(Q_t, H)$. The codebreaker may use the feedback to inform the query $Q_{t+1}$ made in turn $t+1$, and the game ends in turn $s$ if and only if $Q_s = H$.
	
	When $A$ is false, we say that the game is \textit{non-adaptive}. In this case the codebreaker submits $m$ queries $Q_1, Q_2, \ldots, Q_m$ all at once (where the codebreaker chooses $m$). The codemaker then reports a feedback vector of the form $(\Delta(Q_1, H), \Delta(Q_2, H), \ldots, \Delta(Q_m, H))$, after which the codebreaker must submit the final query $\overline{Q}$. The codebreaker wins if and only if $\overline{Q} = H$.
\end{enumerate}

Throughout we define $f(n, k, \Delta, R, A)$ to be the smallest integer such that the codebreaker can determine any hidden sequence $H$ in $f(n, k, \Delta, R, A)$ queries during a game with the corresponding assignment of $n$, $k$, $\Delta$, $R$, and $A$. We will denote true and false by $T$ and $F$, respectively, for assignment of Boolean variables. For example, Donald Knuth's result that the original game of Mastermind (four positions, six colors, black-peg and white-peg, with repeats, and adaptive) can always be determined after four turns (and then guessed on the fifth turn) is equivalently stated as $f(4, 6, \Delta = (b,w), R=T, A=T)\le 4$ (in fact, this bound holds with equality) \cite{DK76}. The case $R = T, A = T$ is the most extensively studied in the literature \cite{CC05,VC83,MG12,DK76}. Doerr, Sp\"{o}hel, Thomas, and Winzen obtain many significant results in the case $R = T$ in \cite{DS13}, applying techniques from \cite{NB09,GK00}. 

We focus only on analyzing the worst-case performance of query strategies for these variants of Mastermind. That is, we always consider the number of queries necessary to guarantee identification of any hidden vector.

Our first main result concerns the Permutation Game, in which $n=k$ and $R=F$, thus restricting the hidden sequence $H$ to be a permutation of the alphabet $\mathcal{A}$.
\begin{theorem}\label{permutationGameTheorem}
	 Consider the Permutation Game defined by $n = k$ and $R = F$. Let $\Delta = b$. Then for all sufficiently large $n$, we have	
 	\begin{equation*}
		f(n, k = n, \Delta = b, R = F, A) \ge n - \log\log(n).
	\end{equation*}
\end{theorem}

Explicit algorithms that take $O(n \log(n))$ turns to solve this variant were developed by Ko and Teng in \cite{KT86}, and Ouali and Sutherland in \cite{OS13}. Ko and Teng approach the problem with an algorithm akin to binary search. The algorithm queries a sequence $Q_t$, swaps two components, and queries again, doing so repeatedly until a previously unknown component of $H$ is determined by the values of the distance function across these repeated queries. Ouali and Sutherland improve this algorithm primarily by altering the search routine after a single component of $H$ has been identified. They also extend their results to variants with $k\ge n$. In this way, they achieve an average factor of two reduction in the number of queries needed to identify $H$. In our notation, these results state that $f(n, k=n, \Delta=b, R = F, A = T)\le O(n\log(n))$.

Via a basic information-theoretic argument, one can show that the Permutation Game also satisfies $f(n, n)\ge n - n/\log(n) + c$ for some constant $c>0$. We improve this lower bound to $f(n, n)\ge n - \log(n)$ for small $n$, and $f(n, n)\ge n- \log \log(n)$ for sufficiently large $n$. To our knowledge, this constitutes the first improvement over the trivial information-theoretic lower bound for the Permutation Game variant of Mastermind.

Our second result concern's Donald Knuth's Minimax algorithm, which was first introduced in 1976.
\begin{theorem}\label{minimaxTheorem}
	Consider the original variant of Mastermind (allowing arbitrary $n$ and $k$), defined by $\Delta=(b, w)$, $R=T$, $A=T$. The Minimax algorithm identifies any hidden sequence $H$ in at most $nk$ queries.
\end{theorem}
Knuth's Minimax algorithm is empirically near-optimal for solving small games of Mastermind ($n$ and $k$ less than 10) in as few guesses as possible. However, it has proven difficult to analyze the asymptotic performance of the Minimax algorithm, primarily because its behavior is determined by the distribution of possibilities for $H$, which is difficult to analyze in general terms \cite{KT86, OS13}. To our knowledge, this is the first upper bound on the worst-case performance of the minimax algorithm, but if it performs near-optimally for large $n$ and $k$, we would expect this bound to be much smaller. We know, for example, that $f(n,k) = O(n \log k)$ for $k$ not too large \cite{DK76, KT86}.

Our third result relates to non-adaptive variants of Mastermind, which correspond to $A=F$ in our notation.
\begin{theorem}\label{nonAdaptiveTheorem}
Consider non-adaptive Mastermind, defined by $A=F$. Let $\Delta = b$, and let $k \geq n$. Then for either choice of $R$, we have
	\begin{equation*}
		f(n, k) = \Omega\left( n\log(k)\right).
	\end{equation*}
\end{theorem}
The case $R = T$ was proved by Doerr, Sp\"ohel, Thomas, and Winzen in \cite{DS13}. They use an information-theoretic argument based on Shannon entropy by letting the hidden sequence be randomly chosen. Shannon entropy is discussed briefly in Section 4.1.
We use a similar argument to extend this to $R = F$, and
% TODO: Need to define our usage of "tight" in the following paragraph.
these lower bounds together cover the case $n \geq k$. For neither choice of $R$ do we have provably optimal upper bounds; when $R = T$ a corollary of a result by Doerr et al. in \cite{DS13} gives an upper bound of $O(k \log k)$ guesses, and for $R = F$ no improvement over the $nk$ bound is known. On the other hand, Doerr et al. are able to extend a result of Chv\'atal in \cite{VC83} to provide tight bounds for $n \le k$ with $R = T$.
\subsection{Structure of the Paper}
Section 2 is dedicated to Theorem 1, and the proof is found in 2.2. Theorem 2 is proved in section 3, and section 4 deals with Theorem 3, with the proof in 4.2.
\section{Adaptive Variants of Mastermind}
\subsection{The Permutation Game}
Here we introduce notation and reasoning used in the proof of Theorem 1. We recall that this deals with the Permutation Game, defined by $n=k$ and $R=F$. We can first show that the information from white-peg responses is irrelevant: These parameters together imply $H=\overline{\sigma}(\mathcal{A})$ for some permutation $\overline{\sigma}\in S_k$ (recalling that $\mathcal{A}=\{1,2,\ldots, k\}$). Moreover, recalling the definition of the white-peg distance function
\begin{equation*}
	w(Q_t, H) = \max_{\sigma\in S_{Q_t}}~b(\sigma(Q_t), H) - b(Q_t, H),
\end{equation*}
and letting $Q_t = \tau(\mathcal{A})$ for some $\tau \in S_k$, we have that with $\sigma = \overline{\sigma}\circ \tau\inv$ we have $\sigma(Q_t) = \overline{\sigma}\circ\tau\inv\circ\tau(\mathcal A)$ which is just $H$, and then $b(\sigma(Q_t),H) = b(H,H)$ achieves the maximum possible value of $n$. Then $w(Q_t,H) = n - b(Q_t,H)$ and is uniquely determined by $b(Q_t,H)$ and so no new information is provided from white-peg responses. As such, for the permutation game we will let $\Delta = b$, as $\Delta = bw$ is precisely the same game.

 As stated in the introduction, an upper bound $f(n, n)\le c\cdot n\log(n)$ was proved in 1986 by Ko and Teng, and in 2013 Ouali and Sutherland improved this constant \cite{KT86, OS13}. Here we establish lower bounds for $f(n, n) = f(n, k=n, \Delta=b, R=F, A=T)$ concerning the Permutation Game.
 
 In this section we will reference the derangements function, denoted $D(n)$ in this paper and $!n$ in some sources. It counts the number of $\{\sigma \in S_n \mid \sigma(i) \neq i,~\forall i\}$. The precise number of such permutations is
 \begin{equation}\label{derangements}
 D(n) = n!\sum_{i=0}^n \frac{(-1)^i}{i!},
 \end{equation}
which is the nearest integer to $n!/e$  \cite{MH03}. 
%TODO: maybe insert a sentence to close this paragraph?
	\subsubsection{Trivial Lower Bound}
	To motivate the result, we begin by establishing the trivial information-theoretic result that
	\begin{equation*}
		f(n, n)\ge \log_{n}(n!) = n-\frac{n}{\ln(n)}+O(1).
	\end{equation*}
	\begin{proof}
		Consider an instance of the Permutation Game with the black-peg-only distance function $\Delta$. To uniquely identify $H$ after $m$ turns, the query response vector $(\Delta(Q_1, H), \Delta(Q_2, H), \ldots, \Delta(Q_m, H))$ must distinguish between all $n!$ permutations of the alphabet $\mathcal{A}$. In the $t\nth$ turn, the codebreaker submits a query sequence $Q_t$, which has $n$ possible associated responses given by $\Delta(Q_t, H)\in\{0, 1, \ldots, n-2, n\}$. We note that it is not possible to get $\Delta(Q_t, H)=n-1$ in the Permutation Game. Therefore there are $n^m$ possible query response vectors of length $m$, hence to identify $H$ in $m$ queries requires that $n^m\ge n!$. This implies $m\ge\log_n(n!)$, and the result follows immediately.
	\end{proof}

	\subsubsection{Buckets}
	To improve upon the trivial lower bound, we first introduce terminology with which to analyze the distribution of the possible solutions after feedback $\Delta(Q_t, H)$ from a given query $Q_t$. Let $\Delta$ be the black-peg-only distance function. For an arbitrary guessing strategy, we let $S_t$ be the set of possible hidden vectors that match the responses to guesses 1 through $t$. For example, $S_0$ is the entire set of $n!$ permutations, and the game is solved exactly when the codebreaker has reduced $S_t$ to a single vector. For each possible query vector $Q_t$, the codebreaker may partition the set $S_{t-1}$ of remaining solutions into subsets which we will call \textit{buckets}; one bucket for each possible response given by the codemaker. We now formalize the notion of a bucket.
	
	Consider the $t\nth$ turn in an instance of the Permutation Game. The codebreaker may use the responses $\Delta(Q_1, H), \Delta(Q_2, H), \ldots, \Delta(Q_{t-1}, H)$ to construct a minimal set $S_{t-1}$ of sequences such that $H\in S_{t-1}$. Suppose the codebreaker submits the query $Q_t = (q_1, q_2, \ldots, q_n)$. Then we define the \textit{bucket $B_t(s)$ implied by response $\Delta(Q_t, H)=s$} to be
	\begin{equation*}
		B_t(s) = \left\{X\in S_{t-1}\mid \Delta(Q_t, X) = s\right\}.
	\end{equation*}
	Such a construct is useful in that if $\Delta(Q_t, H) = s$, the codebreaker may deduce that if a sequence $X\in S_{t-1}t$ satisfies $\Delta(Q_t, X)\neq s$, then $X\neq H$. Therefore the codebreaker may construct the set $S_t$ of possible solutions after the $t\nth$ turn is complete by setting $S_t = B_t(s)$.
	
	We now compute the size of a bucket $B_1(s)$ produced in the first turn of an instance of the Permutation Game. First we choose the $s$ colors that are fixed points with respect to the query sequence $Q_1$. We then permute the remaining $n-s$ colors without any fixed points, which can be done in $D(n - s)$ ways, with $D(i)$ as defined in (\ref{derangements}). Hence we have
	\begin{equation*}
		|B_1(s)| = \binom{n}{s}D(n-s),
	\end{equation*}
	for the bucket implied by response $\Delta(Q_1, H) = s$. Clearly the buckets $B_1(1), B_1(2), \ldots, B_1(n)$ partition the set $S_1$ of $n!$ possible hidden vectors.
	
	The above computation tells us the \textit{initial} size of each bucket, which is independent of the initial query $Q_1$. Now consider the evolution of bucket sizes, \textit{i.e.,} the sequence $|B_1(s)|, |B_2(s)|, |B_3(s)|, \ldots$ over the course of an instance of the Permutation Game. We claim that each of these is bounded by $|B_1(s)|$. Since $|B_1(s)|$ is independent of $Q_1$, assume that $Q_1 = Q_t$. Then the query $Q_t$, together with response $\Delta(Q_t, H)$, produces a bucket $B_t(s)$ defined by $B_1(s)\intersect S_t$ and so $B_t(s) \subseteq B_1(s)$. Hence bucket sizes are bounded above by their initial size, \textit{i.e.,}
	\begin{equation*}
		|B_t(s)|\le |B_1(s)| = \binom{n}{s}D(n-s).
	\end{equation*}

	\subsection{Proof of Theorem 1}
	We now employ the notion of a bucket to improve the trivial lower bound for $f(n, n)$ in the context of the Permutation Game.
	\begin{proof}[Proof]
		 Let $n$ be fixed. We will construct a sequence $L(t)$ that, for any possible guessing strategy, satisfies $L(t) \leq |S_t|$ for some hidden code $H$. 
		 
		 For the proof, we require two technical lemmas: \\
		 The first bounds the sums of sizes of the buckets defined above:
		 \begin{lemma}
		 	\begin{equation*}
		 	\sum_{i=x}^n\binom{n}{i}D(n-i) \le \frac{n!}{x!}.
		 	\end{equation*}
		 \end{lemma}
		 
		 Using this, we construct a sequence $L(t)$, and then prove the following bound on the sequence:
		 \begin{lemma} We recall that $n$ is fixed in defining $L(t)$. For any positive integer $C_n < n$, we have
		 	\begin{equation*}
		 	\frac{L(t)}{n!}\ge \frac{C_{n}! - (H_{C_{n}+t} - H_{C_{n}})}{(C_n+t)!}
		 	\end{equation*}
		 	for all $0\le t\le n-C_{n}$, where $H_n=\sum_{i = 1}^n\frac{1}{i}$ is the $n\nth$ harmonic number.
		 \end{lemma}
		 Proofs of both are provided at the end of the section.\\
		 
		 Now, for $t = n-C_n$ we have
		 \begin{equation*}
		 L(n-C_{n})  \ge n!\left(\frac{C_{n}! - (H_n - H_{C_{n}})}{n!}\right)
		 = C_{n}! - (H_n-H_{C_{n}}).
		 \end{equation*}
		 We choose $C_{n}$ by the following reasoning: we want to achieve a lower bound of $n-C_{n}$ turns to solve the game. This would occur if $L(n-C_n)$ were greater than 1, as there would still be at least 2 possible solutions after $n-C_n$ turns, and thus the game would not yet be solved. Thus, we want
		 \begin{equation*}
		 C_{n}! - (H_n - H_{C_{n}}) > 1.
		 \end{equation*}
		 Noting that $H(n)$ is asymptotic to $\log(n)$, as long as $\log(n) = o(C_n!)$ we will eventually have that $C_n!-H_n > 1$. Since we have, for example, that $\log x = o((\log \log x)!)$, we have that with $C_n = \lceil \log \log(n) \rceil$ the above inequality will eventually be satisfied.
		 
		 In conclusion, when $n$ is sufficiently large, the minimum number of remaining
		 possible solutions after $n - \lceil \log\log(n) \rceil$ guesses is at least
		 \begin{equation*}
		 S_{n - \lceil \log\log(n) \rceil} \geq L(n - \lceil \log\log(n) \rceil)
		 \ge (\log\log(n))! - (H_n - H_{\log\log(n)})
		 > 1.
		 \end{equation*}
		 Thus there is no strategy that can identify any hidden sequence in fewer than $n-\log\log(n)$ turns, and so in the Permutation Game variant of Mastermind, we have $f(n, n)\ge n - \log\log(n)$ for all sufficiently large $n$.
		\end{proof}
		%TODO: I reworked it a bit to add in the ceiling functions. Might need a bit of revision now.
		 
		 
		 \subsection{Proofs of Lemmas 1 and 2}
		 	We begin with Lemma 1:
		 	
		 		\begin{equation*}
		 		\sum_{i=x}^n\binom{n}{i}D(n-i) \le \frac{n!}{x!}.
		 		\end{equation*}
		 
		 	\begin{proof}
		 		We give a combinatorial proof: The left-hand side denotes the number of permutations of an $n$-element vector which have at least $x$ fixed points. Suppose we choose $x$ fixed points and simply permute the rest of the vector. This gives $\binom{n}{x}(n-x)!=\frac{n!}{x!}$ possible permutations. Clearly this includes all vectors with at least $x$ fixed points (and over-counts by some margin), so the inequality holds.
		 	\end{proof}
		 We will now construct $L(t)$ and prove Lemma 2. We recall that $S_t$ is the minimal set of sequences guaranteed to contain $H$ given the responses\\ $\Delta(Q_1, H), \Delta(Q_2, H), \ldots, \Delta(Q_t, H)$. From this definition, we can set $L(0) = n!$ because $S_0$ must contain all $n!$ possible solutions, since no guesses have been made. Next, we construct $L(t)$ inductively from $L(t-1)$ by guaranteeing that when proceeding from $L(t-1)$ to $L(t)$, we eliminate at least as many solutions as any possible guess would eliminate. That is, $L(t-1)-L(t) \geq |S_{t-1}| - |S_{t}|$. This, combined with the assumption that $L(t-1) \le |S_{t-1}|$, guarantees $L(t) \leq |S_t|$, as desired. 
		 %TODO: I've reworked this paragraph a bit. Maybe could still use a bit more, idk.
		 
		 Consider the $t\nth$ turn in an instance of the Permutation Game. In the terminology of buckets, the codebreaker constructs the set $S_{t-1}$ by setting $S_{t-1} = B_{t-1}(\Delta(Q_{t-1}, H))$. To choose an ``optimal'' query sequence $Q_t$ (in the sense described above, which maximizes $|S_{t}| - |S_{t-1}|$), the codebreaker therefore must choose a sequence $Q_t$ which minimizes
		 \begin{equation*}
			\max_{s\in\{1,2,\ldots,n\}}|B_{t}(s)|.
		 \end{equation*}
		 Equivalently, the codebreaker chooses $Q_t$ such that the size of the largest bucket is as small as possible. By the discussion in Section (2.1.2), we know that $|B_t(s)|\le\binom{n}{s}D(n-s)$. The optimal query $Q_t$ will partition $S_{t-1}$ into buckets as evenly as possible, and some buckets will have size equal to their upper bound, while others will be partially filled. This best-possible partition will partition $S_{t-1}$ into two sets $X$ and $Y$ of buckets, such that $A\in X$ implies bucket $A$ is incompletely filled, $B\in Y$ implies bucket $B$ is completely filled, and $A\in X$, $B\in Y$ implies that the upper bound on $|A|$ is greater than the upper bound on $|B|$. Let $x = |X|$, so that $x$ is the number of incompletely filled buckets.
		 
		 We now give a recurrence which bounds $L(t)$. At the beginning of the $t^\text{th}$ turn, we have at least $L(t-1)$ possible solutions remaining, so $|S_{t-1}|\ge L(t-1)$. Suppose that the codebreaker has selected the optimal query vector $Q_t$ for submission in turn $t$. We then have 
		\begin{align}\label{recur}
			L(t-1)
			& \le \sum_{i = 0}^{n}|B_i(t)|\nonumber\\
			& = \sum_{i=0}^{x-1}|B_i(t)| + \sum_{i=x}^{n}|B_i(t)|\nonumber\\
			& \le \sum_{i = 0}^{x-1}L(t) + \sum_{i=x}^{n}\binom{n}{i}D(n-i)\quad
			\text{for optimal $x$}\nonumber\\
			& = x\cdot L(t) + \sum_{i = x}^{n}\binom{n}{i}D(n-i).
		\end{align}
		Now we find the $x$ that generates this optimal distribution and solve for $L(t)$. Once we know $L(t)$, we claim that the inequality in equation (\ref{recur}) holds for all $x$. Picking $x$ larger than its optimal value increases the contribution of some of the entirely filled, smaller buckets up to $L(t)$, thus increasing the total sum. Picking $x$ too small increases the contribution of some of the under-filled, larger buckets up to their full sizes, thereby increasing the total sum. So adjustment of $x$ about its optimal value always preserves the inequality. Thus (\ref{recur}) holds for all $x$.

		
		From Lemma 1 and (\ref{recur}), we have
		\begin{equation*}
			L(t-1) \le x\cdot L(t) + \frac{n!}{x!},
		\end{equation*}
		which gives
		\begin{equation*}
			L(t)\ge \frac{1}{x}\left(L(t-1)-\frac{n!}{x!}\right).
		\end{equation*}
		
		We are now ready to prove Lemma 3: \\
		For any positive integer $C_n < n$, we have
			\begin{equation*}
				\frac{L(t)}{n!}\ge \frac{C_{n}! - (H_{C_{n}+t} - H_{C_{n}})}{(C_n+t)!}
			\end{equation*}
			for all $0\le t\le n-C_{n}$, where $H_n=\sum_{i = 1}^n\frac{1}{i}$ is the $n\nth$ harmonic number.
		\begin{proof} We prove inductively. With $t=0$, we have $L(0) = n!$. Then
			\begin{equation*}
			1 =\frac{L(0)}{n!}\ge \frac{C_{n}! - (H_{C_{n}}-H_{C_{n}})}{C_{n}!} = 1,
			\end{equation*}
			and the inequality is satisfied. Now we move to the general case.
			Recalling that (\ref{recur}) holds for all $x$, we will
		let $x=t+C_{n}$. Solving for $L(t)$ gives us
		
			\begin{equation*}
			\frac{L(t)}{n!}
			 \ge \frac{1}{C_{n}+t}\left(\frac{L(t-1)}{n!}
			-\frac{1}{(C_{n}+t)!}\right).
			\end{equation*}
		Assuming the lemma inductively for $t-1$, we obtain
			\begin{align*}
			\frac{L(t)}{n!}
			& \ge \frac{1}{C_{n}+t}\left(\frac{C_{n}!-(H_{C_{n}+t} - H_{C_{n}})}
			{(C_{n}+t-1)!} - \frac{1}{(C_{n}+t)!}\right)\\
			& \ge \left(\frac{C_{n}! - (H_{C_{n}+t-1} - H_{C_{n}}) - \frac{1}{C_{n}+t}}
			{(C_{n}+t)!}\right)\\
			& \ge \left(\frac{C_{n}! - (H_{C_{n}+t} - H_{C_{n}})}{(C_{n}+t)!}\right),
			\end{align*}
			which completes the induction.
		\end{proof}

	

\section{Linear Algebra and the Minimax Algorithm}
This section is dedicated to the proof of Theorem 2, which deals with the Minimax algorithm. To perform this analysis, we first change our notation. We can represent all guess vectors and hidden vectors as $(0,1)$-vectors in $\R^{nk}$, which for convenience we write with two indices $A_{ij} = A_{(i-1)n+j}$, with $i$ ranging from $1$ to $n$ and $j$ from $1$ to $k$.  These vectors are constructed in the following manner: 
$$
A_{ij} = \begin{cases}
1 & \text{this guess assigns the $i^\text{th}$ spot the $j^\text{th}$ color} \\
0 & \text{otherwise}
\end{cases}
$$. As such, each set of indices $A_{i1},\dots,A_{ik}$ will have exactly one 1, as the $i^\text{th}$ position is exactly one color. We refer to these vectors as \textit{representations} of the guess and hidden vectors.

With this notation, the black-peg distance becomes the dot product of the representations of the guess and the hidden vector, as there will be a contribution to the dot product exactly when both representations have a one in the same $A_{ij}$, i.e. there is the same color in the same spot of both vectors. 

The goal of Mastermind is then to find the (necessarily unique) valid representation such that its dot product with the hidden vector is $n$. By linearity of the dot product, once we know the value of the dot product of the hidden vector with some set of guess vectors, we know the value of the dot product of the hidden vector with any vector in the span of these guesses. Therefore, it is an immediate consequence that a winning strategy can be found by querying a basis for the span of the valid guess vectors, which, as a subspace of $\R^{nk}$, must be of size at most $nk$. Note that this strategy does not make use of adaptive feedback, of white-peg responses, or the condition on repeated colors. Thus, for any choice of $\Delta$, $A$, and $R$, we have $f(n,k) \leq nk$.

This representation also allows us to bound the minimax algorithm of \cite{DK76}. 
\subsection{Proof of Theorem 2}
The bulk of the proof lies in the following lemma:
\begin{lemma}
	At each turn, the minimax algorithm either guesses the hidden vector or guesses a vector whose representation is linearly independent of the previous guesses' representations.
\end{lemma}

\begin{proof}
	If the hidden vector is known, the minimax algorithm will guess it. This will certainly occur when the hidden vector's representation is a linear combination of the previous guess vectors' representations, as by the logic above we can compute the dot products of the hidden vector with every possibility in the span of the previous guesses, and we would find the guess with a dot product of $n$.
	
	Otherwise, the hidden vector is linearly independent from the previous guess vectors. Assume this is the case. If it is still uniquely determined, the algorithm will guess it. Regardless, guessing a vector $q$ that is a linear combination of the previous guesses returns no new information, as the response to that guess can already be computed. Since $q$ is linearly dependent on the previous guesses, it cannot, by our assumption, be the hidden vector, and so guessing it eliminates zero vectors and doesn't solve the game. If we can find a new query $r$ that is guaranteed to either eliminate at least one vector or solve the game, the minimax algorithm will choose $r$ over $q$. Since the hidden vector must exist and by our assumption is linearly independent of the guess vectors, there is at least one vector linearly independent of the previous guesses. Guessing such a vector will win the game with a black-peg response of $n$, and eliminate at least one vector (itself) with any other response. Thus, according to the minimax algorithm, guessing any vector linearly independent of the previous guesses will always be strictly better than guessing a linearly dependent vector, and so if the hidden vector is unknown the best guess will be necessarily independent of the previous guesses.
\end{proof}
Theorem \ref{minimaxTheorem} follows as an immediate corollary from this lemma: Since these representations are in $\R^{nk}$, the minimax algorithm can make at most $nk$ linearly independent guesses. After that, the minimax cannot make a linearly independent guess and by the above lemma must then guess the hidden vector, for an upper bound of $nk$ turns to determine the hidden vector and one more turn to guess it.

\section{Non-Adaptive Variants}
This section follows closely the reasoning of Doerr et al. \cite{DS13} as they analyze non-adaptive games.  We perform an analysis of the Mastermind variant in which $\Delta$ is the black-peg-only distance function, $R=F$ and $A=F$ (\textit{i.e.,} no repeats and non-adaptive). We first introduce Shannon entropy, which we then employ to give a lower bound for $f(n,k)$ when no repeats are allowed. We conclude with a small extension of one of the proofs due to Doerr et al. to provide an upper bound on $f(n,k)$ for non-adaptive variants when $k\ge n$.
\subsection{Shannon Entropy}\label{ssec:shannonEntropy}
First we give a brief definition of entropy in the context of information theory, where it is often called \textit{Shannon entropy}. Our presentation %TODO wrong word
 borrows from \cite{DG14}. Shannon entropy is intuitively the ``expected level of surprise'' of a random variable, and hence is based upon the definition of a surprise function $S$. For random variable $X$, and possible event $X=x$, we define $S(x)=-\log_2(\mathbb{P}[X=x])$. Let $X$ and $Y$ be a random variables and let $X=x$ and $Y=y$ be events. The surprise function $S$ then satisfies $S(X=x\land Y=y) = S(X=x) + S(Y=y\mid X=x)$ \cite{DG14}.

Let $D$ be the domain of the random variable $X$. Then the \textit{Shannon entropy} $H(X)$ of the random variable $X$ is defined to be
\begin{align*}
	H(X)
	& = \mathbb{E}[S(x)]\\
	& = \sum_{x\in D}\mathbb{P}[X=x]\cdot (-\log_2(\mathbb{P}[X=x])).
\end{align*}
One can easily show that Shannon entropy is \textit{subadditive} \cite{DG14}. That is, if $X_1, X_2, \ldots, X_n$ are random variables, then
	\begin{equation}\label{subadditivityDefinition}
			H(X_1, X_2, \ldots, X_n)\le \sum_{i=1}^{n}H(X_i).
	\end{equation}
We will use Shannon entropy in the following proof.

\subsection{Proof of Theorem 3}

\begin{proof}
	We prove Theorem \ref{nonAdaptiveTheorem} in the case $R = F$, noting that \cite{DS13} have already proved the case $R=T$. We will be drawing substantially from the techniques they use in their proof. Consider a set $\{Q_1, Q_2, \ldots, Q_s\}$ of $s$ query sequences such that all $k!/(k-n)!$ possible hidden sequences are uniquely determined by the responses $\Delta(Q_1, H), \Delta(Q_2, H), \ldots, \Delta(Q_s, H)$. That is, assume that if two possible hidden vectors $H$ and $H'$ satisfy $\Delta(Q_i, H) = \Delta(Q_i, H')$ for all $i$, then $H = H'$.

	Let the hidden vector $Z$ be sampled uniformly at random from the set of $k!/(k-n)!$ possibilities. Then the responses $Y_i = b(Z, q_i)$ are now random variables, and the vector $Y = (Y_1, Y_2, \ldots, Y_s)$ is also a random variable. By our assumptions, $Y$ always uniquely determines, and is uniquely determined by, $Z$. This bijection of events  $Z=z$ with events $Y=y$ shows that $H(Z) = H(Y)$. Since $Z$ is a random variable with $k!/(k-n)!$ outcomes of equal probability, we compute
	\begin{equation}\label{equalEntropy}
		H(Z) = \log_2\left(\frac{k!}{(k-n)!}\right).
	\end{equation}
	By (\ref{subadditivityDefinition}), we have
	\begin{equation}\label{entropySum}
		H(Y)\le\sum_{i=1}^s H(Y_i).
	\end{equation}
	Now we bound $H(Y_i)$. We recall that by assumption, $\Delta = b$ so $Y_i$ is precisely the black-peg distance between $Q_i$ and $Z$. By definition,
	\begin{equation}\label{entropyDef}
		H(Y_i)=-\sum_{x=0}^n \mathbb{P}[Y_i=x]\cdot\log_2(\mathbb{P}[Y_{i}=x]).
	\end{equation}
	We now compute $\mathbb{P}[Y_i=x]$, namely the probability that $X$ is a solution vector with $x$ fixed points with respect to the query $q_i$. Using our previous terminology, this is the probability that $X$ is in bucket $B(x)$.
	$|B(x)|$ is the number of ways to have exactly $x$ fixed points, which is less than the number of ways to choose $x$ fixed points, and then choose any colors on the rest of the elements. Thus:
	\begin{align*}
		\mathbb{P}[Y_i = x] &= \frac{|B(x)|}{\left(\frac{k!}{(k-n)!}\right)}\\
		&\leq \frac{\binom{n}{x}\frac{(k-x)!}{(k-n)!}}{\left(\frac{k!}{(k-n)!}\right)}\\
		&= \frac{1}{x!}\cdot\frac{n(n-1)\cdots(n-x+1)}{k(k-1)\cdots(k-x+1)}\\
		&\leq \frac{1}{x!}.
	\end{align*}
	It turns out that we can't substitute this upper bound into  (\ref{entropyDef}) for all $x$, because $f(\alpha)=-\alpha\log_2\alpha$ is an increasing function only when $\alpha<1/e$. So we can plug in the upper bound of $\text{Pr}[X=x]\le 1/x!$ when $x\ge 3$ and still have an upper bound. For the first three values of $x$, we instead use the trivial upper bound $f(\alpha)\le 1/(e\log 2)$. Then
	\begin{align*}
		H(Y_i) &\leq \frac{3}{e\log 2}+\sum_{x=3}^n-\frac{1}{x!}\cdot\log_2\left(\frac{1}{x!}\right)
		\le \frac{3}{e\log 2}+\sum_{x=3}^\infty \frac{\log_2(x!)}{x!}
		<3.
	\end{align*}
	Combining this with (\ref{entropySum}) gives $H(Y) \leq 3s$, and since $H(Z) = H(Y)$ we have $H(Z) \leq 3s$. Substituting in (\ref{equalEntropy}) as a lower bound for $H(Z)$ and solving for $s$ gives
	\begin{equation*}
	s \geq \frac{1}{3}\log_2\left(\frac{k!}{(k-n)!}\right).
	\end{equation*}
	
	We can show that the right-hand side is $\Omega(n\log k)$. This is immediate for large $k$ relative to $n$ by bounding the ratio by $(k-n)^n$; for small $k$ (e.g. $k \leq 2n$) we bound the ratio by $n!$ and the claim follows from Stirling's approximation. So this gives us a lower bound of $\Omega(n \log k)$ turns for any non-adaptive strategy for Mastermind with no repeats and black-peg responses.
	%TODO: add more perhaps?
\end{proof}
\subsubsection{Extension to white-peg responses}
We extend the $R=T$ case of Theorem \ref{nonAdaptiveTheorem}, as proved in $\cite{DS13}$, to include $\Delta = bw$. We show that any black-white strategy must submit $\Omega(k)$ queries, and that we can convert a black and white-peg strategy into a black-peg-only strategy by adding $O(k)$ queries. 
Then changing a black-white strategy to a black-only strategy changes the number of queries by at most some absolute constant factor. So we have $f(\Delta = b) = O(f(\Delta = bw))$. Combining this with Theorem 3 implies the theorem for black-white responses as well.

First we describe the conversion. Take a black-white strategy and append, for each color, a query where every spot is that color. As a black-peg only strategy, we can deduce from these queries exactly how many times each color appears in the hidden vector, from which we can determine the white-peg responses to any of the original queries. Therefore, if the old strategy had enough information to determine the hidden vector with black-white responses, this new strategy can determine the hidden vector with just black-peg responses. Since there are $k$ colors, we have appended $k$ queries in this conversion. 

Lastly, we show that any non-adaptive black-white strategy must submit $\Omega(k)$ queries. Assume that there are two colors $a$ and $b$ such that a non-adaptive strategy guesses neither $a$ nor $b$ in either spot 1 or 2. Then this strategy would not be able to distinguish between a hidden vector starting $a,b$ and one starting $b,a$. Then by contradiction any non-adaptive strategy must guess at least $k-1$ colors in these two spots. It can guess 2 colors in these spots per turn, for a total of at least $(k-1)/2 = \Omega(k)$ turns required to solve the game. Thus, by the above logic, we conclude $f(n,k) = \Omega(n \log k)$ in this case as well.

\subsection{An Upper Bound for Non-Adaptive Variants with Repeats}
Consider non-adaptive variants of Mastermind in which repetitions are allowed. First we note that when $k=n$, \cite{DS13} showed the existence of a set of $O(n \log(n))$ queries which uniquely identify any hidden sequence $H$. When $k > n$, one can simply extend $H$ and all queries $Q_t$ by $k - n$ ``auxiliary'' positions until $n = k$. We fill these auxiliary positions with arbitrary colors, and we adjust the responses accordingly to account for the auxiliary positions. By the results of \cite{DS13}, there exists a set of $O(k \log k)$ queries which will uniquely identify any hidden sequence.

\section{Acknowledgments}
We would like to thank Daniel Montealegre for supervising and assisting our work throughout the summer, and Nathan Kaplan for both creating and guiding our project and for his invaluable assistance in editing this paper. 
 We would also like to thank Sam Payne and the Summer Undergraduate Math Research at Yale program for organizing, funding, and supporting this project. SUMRY is supported in part by NSF grant CAREER DMS-1149054.
\clearpage
\bibliographystyle{acm}
\bibliography{QCMV_Bibliography}

\end{document}

























