% Author and Title Information
\newcommand*{\thetitle}{Query Complexity of Mastermind Variants}
\newcommand*{\theauthor}{Aaron Berger\quad Christopher Chute\quad Matthew Stone}
\newcommand*{\duedate}{December 26, 2015}

% Document Settings
\documentclass[12pt, a4paper]{article}
\author{\theauthor}
\title{\thetitle}
\date{\duedate}
\usepackage[top=.75in, left=0.5in, right=0.5in, bottom=1.5in]{geometry}
\usepackage{amsmath, amsthm, amssymb}
\newtheorem{lem}{Lemma}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage[T1]{fontenc}
\usepackage{titling}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[nottoc]{tocbibind}

\setlength{\droptitle}{-4em}
\posttitle{\par\end{center}\vspace{-.35em}}

% Header Formatting
%\usepackage{fancyhdr}
%\setlength{\headheight}{48pt}
%\pagestyle{fancyplain}
%\lhead{\thetitle}
%\rhead{\theauthor\\\duedate}
%\rfoot{}
%\cfoot{\thepage}

% Math Macros
\newcommand{\R}{\mathbb{R}}           % Real numbers
\newcommand{\Z}{\mathbb{Z}}           % Integer numbers
\newcommand{\Q}{\mathbb{Q}}           % Rational numbers
\newcommand{\N}{\mathbb{N}}           % Natural numbers
\newcommand{\C}{\mathbb{C}}           % Complex numbers
\newcommand{\F}{\mathbb{F}}           % Field (e.g, Z mod pZ)
\newcommand*{\bigbar}{\overline}      % Overline
\newcommand*{\ihat}{\hat{\imath}}     % i-hat
\newcommand*{\jhat}{\hat{\jmath}}     % j-hat
\newcommand{\lcm}{\text{l.c.m.}}      % Least common multiple
\newcommand{\union}{\cup}             % Set union
\newcommand{\intersect}{\cap}         % Set intersection
\newcommand{\im}{\text{im}}           % Image of a function
\newcommand{\vphi}{\varphi}           % Attractive phi
\newcommand{\normal}{\trianglelefteq} % Is a normal subgroup of
\newcommand{\abel}{^{\text{ab}}}      % Abelianization
\newcommand{\Aut}{\text{Aut}}         % Automorphisms
\newcommand{\Hol}{\text{Hol}}         % Holomorph
\newcommand{\inv}{^{-1}}              % Inverse
\newcommand{\nth}{^{\text{th}}}       % Superscript n-th

\begin{document}
\maketitle
\begin{abstract}
	We study variants of Mastermind, a popular board game in which the objective is sequence reconstruction. In this two-player game, the codemaker constructs a hidden sequence $H = (h_1, h_2, \ldots, h_n)$ of colors selected from an alphabet $\mathcal{A} = \{1,2,\ldots, k\}$ (\textit{i.e.,} $h_i\in\mathcal{A}$ for all $i\in\{1,2,\ldots, n\}$). The game then proceeds in turns, each of which consists of two parts: in turn $t$, the codebreaker first submits a query sequence $Q_t = (q_1, q_2, \ldots, q_n)$ with $q_i\in \mathcal{A}$ for all $i$, and second receives feedback $\Delta(Q_t, H)$, where $\Delta$ is a function of distance between two $n$-sequences. The game terminates when $Q_t = H$, and the codebreaker seeks to end the game in as few turns as possible. Throughout we let $f(n,k)$ denote the smallest integer such that the codebreaker can determine any $H$ in $f(n,k)$ turns.\cite{VC83} We prove three main results: First, we show that given a set $S_{t}$ of sequences which is known to contain $H$, there always exists a query whose feedback implicitly produces a smaller set $S_{t+1}$ such that $H\in S_{t+1}$ and $|S_{t+1}|\le (1-1/(nk))|S|$. Second, when $H$ is known to be a permutation of the alphabet $\{1,2,\ldots, n\}$, we prove that $f(n, n)\ge n - \log\log(n)$ for all sufficiently large $n$. Third, when feedback is not received until all queries have been submitted, we show that there exists a constant $c>0$ such that $f(n,k)\ge c\cdot n\log(k)$.
\end{abstract}

\section{Introduction}

Variants of Mastermind are a family of two-player games centered around reconstruction of a hidden sequence. In all variants of the game, one player is given the role of ``codemaker,'' and the other is denoted the ``codebreaker.'' The codemaker begins the game by constructing a hidden sequence $H = (h_1, h_2, \ldots, h_n)$ where each component is selected from an alphabet $\mathcal{A} = \{1,2,\ldots,k\}$ of $k$ colors (that is, $h_i\in\mathcal{A}$ for all $i\in\{1,2,\ldots,n\}$). The goal of the codebreaker is to uniquely determine the hidden sequence $H$ through a series of queries, which are submissions of vectors of the form $Q_t = (q_1, q_2, \ldots, q_n)$. The codebreaker always seeks to determine $H$ with as few queries as possible, however the nature of these queries, the feedback received after a query, and the restrictions on $H$ differ between variants.

The variants which we will study are differentiated by settings of the tuple $(n, k, \Delta, R, A)$. These parameters are defined as follows:
\begin{enumerate}[label=(\roman*)]
	\item ($n$) \textit{Length of Sequence.} The parameter $n$ denotes the length of the hidden sequence $H$ created by the codemaker, hence $H = (h_1, h_2, \ldots, h_n)$. The codebreaker is also required to submit query vectors of length $n$, so the $t\nth$ query vector takes the form $Q_t = (q_1, q_2, \ldots, q_n)$.
	
	\item ($k$) \textit{Size of Alphabet.} This parameter determines the number of possible values for components of $H$ and $Q_t$. Each game is accompanied by an alphabet $\mathcal{A} = \{1,2,\ldots,k\}$ from which the components of $H$ and $Q_t$ are selected. That is, $h_i\in\{1,2,\ldots,k\}$ and $q_i\in\{1,2,\ldots,k\}$.
	
	\item($\Delta$) \textit{Distance Function.} On the $t\nth$ turn of a game, the codebreaker submits a query sequence $Q_t = (q_1, q_2, \ldots, q_n)$. The codemaker then gives feedback $\Delta(Q_t, H)$, which is roughly a measure of distance between $Q_t$ and $H$. The information yielded by $\Delta(Q_t, H)$ may be used to guide the choice of $Q_{t+1}$, the next sequence to be guessed. Hence the choice of distance function affects the codebreaker's ability to make an informed query on the following turn. We study the following distance functions:
	\begin{enumerate}[label=\alph*.]
		\item\textit{``Black-peg and white-peg.''} Let $Q_t$ and $H$ be as above. The black-peg and white-peg distance function is defined by $\Delta(Q_t, H) = (b(Q_t, H), w(Q_t, H))$ where
		\begin{equation}
			b(Q_t, H) = \left|\{i\in\Z\mid q_i = h_i,~ 1\le i\le n\}\right|,
		\end{equation}
		and
		\begin{equation*}
			w(Q_t, H) = \max_{\sigma\in S_{Q_t}}~b(\sigma(Q_t), H) - b(Q_t, H),
		\end{equation*}
		We note that this is the distance function used in the original game of Mastermind.

		\item\textit{``Black-peg-only.''} When $\Delta$ is the black-peg-only distance function, it is defined by $\Delta(Q_t, H) = b(Q_t, H)$, where $b$ is defined as in equation (1).
	\end{enumerate}
	
	\item($R$) \textit{Repetition.} The parameter $R$ is a Boolean restriction on the components of $H$. If $R$ is true, we say that the variant game is \textit{with repeats} or that repeats are allowed. In this case, the hidden vector $H$ may have repeated colors, that is, we allow $h_i = h_j$ for any $i,j\in\{1,2,\ldots, n\}$. When $R$ is false, we say that the variant is \textit{no repeats}, and we require $h_i\neq h_j$ when $i\neq j$. In particular, when $R$ is false and $k = n$, we have that $H$ must be a permutation of $(1, 2, \ldots, n)$, and we refer to this variant as the \textit{Permutation Game.}
	
	\item($A$) \textit{Adaptiveness.} The Boolean parameter $A$ determines whether the codebreaker receives feedback after each query. If $A$ is true, we say that the game is \textit{adaptive}. In this case the game consists of two-part turns: on the $t\nth$ turn, the codebreaker first submits a query sequence $Q_t$, and then receives feedback $\Delta(Q_t, H)$. The codebreaker may use the feedback to inform the query $Q_{t+1}$ made in turn $t+1$, and the game ends in turn $s$ if and only if $Q_s = H$.
	
	When $A$ is false, we say that the game is \textit{non-adaptive}. In this case the codebreaker submits $m$ queries $Q_1, Q_2, \ldots, Q_m$ all at once (where the codebreaker chooses $m$). The codemaker then reports a feedback vector of the form $(\Delta(Q_1, H), \Delta(Q_2, H), \ldots, \Delta(Q_m, H))$, after which the codebreaker must submit the final query $\overline{Q}$. The codebreaker wins if and only if $\overline{Q} = H$.
\end{enumerate}

Throughout we define $f(n, k, \Delta, R, A)$ to be the smallest integer such that the codebreaker can determine any hidden sequence $H$ in $f(n, k, \Delta, R, A)$ queries during a game with the corresponding assignment of $n$, $k$, $\Delta$, $R$, and $A$. We will denote true and false by $T$ and $F$, respectively, for assignment of Boolean variables. For example, Donald Knuth's result that the original game of Mastermind (four positions, six colors, black-peg and white-peg, with repeats, and adaptive) can always be determined after four turns is equivalently stated as $f(4, 6, \Delta = (b,w), R=T, A=T)\le 4$ (in fact, this bound holds with equality). We will write simply $f(n, k)$ when the context is clear.

We prove three main results, each of which builds on the previous work related to a given Mastermind variant.
\begin{enumerate}[label=]
	\item\textbf{Theorem 1.} Let $A=T$, let $\Delta$ be the black-peg-only distance function, and let $n$, $k$, and $R$ be fixed. Given a set $S_{t}$ of sequences which is known to contain $H$, there exists a query whose feedback produces a smaller set $S_{t+1}$ such that $H\in S_{t+1}$ and $|S_{t+1}|\le (1-1/(nk))|S|$.
\end{enumerate}
This theorem facilitates analysis of a common variant of Mastermind, in which adaptive queries are made with feedback given by the black-peg-only distance function. To demonstrate the theorem's usefulness, suppose that the codebreaker is in turn $t$, hence has made queries $Q_1, Q_2 \ldots, Q_{t-1}$ and received feedback instances $\Delta(Q_1, H), \Delta(Q_2, H) \ldots, \Delta(Q_{t-1},H)$. Given this set of feedback, the codebreaker can eliminate a number of possibilities for $H$. For example, suppose that a sequence $\tilde{H} = (\tilde{h}_1, \tilde{h}_2 \ldots, \tilde{h}_n)$ satisfies $\Delta(\tilde{H}, H)\neq \Delta(Q_s, H)$ for some $s\in\{1,2,\ldots, t-1\}$. Then clearly $\tilde{H}\neq H$.

Using this process, the codebreaker may construct a set $S_t$ of possibilities for $H$ in turn $t$ after $t-1$ query-feedback interactions have occurred. That is, $S_t$ contains sequences of length $n$ with components from the alphabet $\mathcal{A}$ such that no member of $S_t$ has been eliminated by the responses $\Delta(Q_1, H), \Delta(Q_2, H), \ldots, \Delta(Q_{t-1}, H)$. Theorem 1 then states that given $S_t$, there always exists a query $Q_t$ such that the response $\Delta(Q_t, H)$ will eliminate a fraction $1/(nk)$ of the members of $S_t$ as possibilities for $H$. By Theorem 1, $|S_{t+1}|\le (1-1/(nk))|S_{t}|$, which guarantees a quantifiable amount of progress at each turn of an adaptive, black-peg-only variant of mastermind.

Our second main result concerns the Permutation Game, in which $n=k$ and $R=F$, thus restricting the hidden sequence $H$ to be a permutation of the alphabet $\mathcal{A}$.
\begin{enumerate}[label=]
	\item\textbf{Theorem 2.} Consider the Permutation Game defined by $n = k$ and $R = F$. Let $\Delta = b$ (black-peg-only distance function) and let $A$ be fixed. Then for all sufficiently large $n$, we have
	\begin{equation*}
		f(n, k = n, \Delta = b, R = F, A) \ge n - \log\log(n).
	\end{equation*}
\end{enumerate}
Explicit algorithms that take $O(n \log n)$ turns to solve this variant were developed by Ko and Teng\cite{KT86}, and Ouali and Sutherland\cite{OS13}. Ko and Teng approach the problem with an algorithm akin to binary search. The algorithm queries a sequence $Q_t$, swaps two components, and queries again, doing so repeatedly until a previously unknown component of $H$ is determined by the values of the distance function across these repeated queries. Ouali and Sutherland improve this algorithm primarily by altering the search routine after a single component of $H$ has been identified. In this way, Ouali and Sutherland achieve an average factor of 2 reduction in the number of queries needed to identify $H$. In our notation, these results state that there exists a constant $c>0$ such that $f(n, k=n, \Delta=b, R = F, A = T)\le c\cdot n\log(n)$.

Via a basic information-theoretic argument, one can show that the Permutation Game also satisfies $f(n, n)\ge n - n/\log(n) + c$ for some constant $c>0$. We improve this lower bound to $f(n, n)\ge n - \log(n)$ for small $n$, and $f(n, n)\ge n- \log \log(n)$ for sufficiently large $n$. To our knowledge, this constitutes the first improvement over the trivial information-theoretic lower bound for the Permutation Game variant of Mastermind.

Our third result relates to non-adaptive variants of Mastermind, which correspond to $A=F$ in our notation.
\begin{enumerate}[label=]
	\item\textbf{Theorem 3.} Consider non-adaptive Mastermind, defined by $A=F$. Let $\Delta$ be the black-peg-only distance function, and let $n$, $k$, and $R$ be fixed. Then there exists a constant $c>0$ such that
	\begin{equation*}
		f(n, k, \Delta = b, R, A=F)\ge c\cdot n\log(k).
	\end{equation*}
\end{enumerate}
This theorem was proved by Ouali and Sutherland\cite{OS13} for the case $R = T$. They use an information-theoretic argument based on entropy by letting the hidden sequence be randomly chosen. 
% TODO: insert more explanation
 We use a similar argument to extend this to $R = F$. 

% TODO: Perhaps we should emphasize somewhere in the intro that we're only looking at worst-case analysis but provide some references to expected-case papers
\clearpage

To our knowledge, there have been no previous attempts to provide a lower bound for $f(n,k)$ in non-adaptive variants of Mastermind. With regard to an upper bound, we have the following result due to Vaclav Chvatal:\cite{VC83} \textit{For every positive $\epsilon$ there is an $n(\epsilon)$ with the following property: if $n>n(\epsilon)$ and if $k<n^{1-\epsilon}$ then}
\begin{equation*}
	f(n, k, \Delta = b, R, A=F)\le (2 + \epsilon)n\frac{1+2\log(k)}{\log(n) - \log(k)}.	
\end{equation*}
Chvatal's proof of the above result relies on a probabilistic argument, showing that there always exists a set of $(2 + \epsilon)(n)(1+2\log(k))/(\log(n) - \log(k))$ queries such that the responses (\textit{i.e.,} values of $\Delta(Q_t, H)$) will differentiate between each possible hidden vector $H$.
% TODO: this was improved/extended by Doerr et. al. Fix this paragraph.

\section{Adaptive Variants of Mastermind}
\subsection{The Permutation Game}
We begin by performing an analysis of the Permutation Game, defined by $n=k$ and $R=F$. These parameters together imply $H=\sigma(\mathcal{A})$ for some permutation $\sigma\in S_k$ (recalling that $\mathcal{A}=\{1,2,\ldots, k\}$). As stated in the introduction, an upper bound $f(n, n)\le c\cdot n\log(n)$ was proved in 1986 by Ko and Teng, and again in 2013 for a smaller constant $c>0$ by Ouali and Sutherland. Here we establish lower bounds for $f(n, n) = f(n, k=n, \Delta=b, R=F, A=T)$ concerning the Permutation Game.

	\subsubsection{Trivial Lower Bound}
	We begin by establishing the trivial information-theoretic result that
	\begin{equation*}
		f(n, n)\ge \log_{n}(n!) = n-\frac{n}{\ln(n)}+O(1).
	\end{equation*}
	\begin{proof}
		Consider an instance of the Permutation Game with the black-peg-only distance function $\Delta$. To uniquely identify $H$ after $m$ turns, the query response vector $(\Delta(Q_1, H), \Delta(Q_2, H), \ldots, \Delta(Q_m, H))$ must distinguish between all $n!$ permutations of the alphabet $\mathcal{A}$. In the $t\nth$ turn, the codebreaker submits a query sequence $Q_t$, which has $n$ possible associated responses given by $\Delta(Q_t, H)\in\{0, 1, \ldots, n-2, n\}$. We note that it is not possible to get $\Delta(Q_t, H)=n-1$ in the Permutation Game. Therefore there are $n^m$ possible query response vectors of length $m$, hence to identify $H$ in $m$ queries requires that $n^m\ge n!$. This implies $m\ge\log_n(n!)$, and the result follows immediately.
	\end{proof}

	\subsubsection{Buckets}
	To improve upon the trivial lower bound, we first introduce terminology with which to analyze the distribution of the possible solutions after feedback $\Delta(Q_t, H)$ from a given query $Q_t$. Let $\Delta$ be the black-peg-only distance function. Given a query vector $Q_t$, the codebreaker may partition the set $S_t$ of remaining solutions into subsets which we will call \textit{buckets}; one bucket for each possible response given by the codemaker. We now formalize the notion of a bucket.
	
	Consider the $t\nth$ turn in an instance of the Permutation Game. As described in the introduction, the codebreaker may use the responses $\Delta(Q_1, H), \Delta(Q_2, H), \ldots, \Delta(Q_{t-1}, H)$ to construct a minimal set $S_t$ of sequences such that $H\in S_t$. Suppose the codebreaker submits the query $Q_t = (q_1, q_2, \ldots, q_n)$. Then we define the \textit{bucket $B_t(s)$ implied by response $\Delta(Q_t, H)=s$} to be
	\begin{equation*}
		B_t(s) = \left\{X\in S_t\mid \Delta(Q_t, X) = s\right\}.
	\end{equation*}
	Such a construct is useful in that if $\Delta(Q_t, H) = s$, the codebreaker may deduce that if a sequence $X\in S_t$ satisfies $\Delta(Q_t, X)\neq s$, then $X\neq H$. Therefore the codebreaker may construct the set $S_{t+1}$ of possible solutions after the $t\nth$ turn is complete by setting $S_{t+1} = B_t(s)$.
	
	We now compute the size of a bucket $B_1(s)$ produced in the first turn of an instance of the Permutation Game. First we choose the $s$ colors that are fixed points with respect to the query sequence $Q_1$. We then permute the remaining $n-s$ colors without any fixed points, giving $D(n - s)$, the derangements on an $(n-s)$-element vector. Hence we have
	\begin{equation*}
		|B_1(s)| = \binom{n}{s}D(n-s),
	\end{equation*}
	for the bucket implied by response $\Delta(Q_1, H) = s$. Clearly the buckets $B_1(1), B_1(2), \ldots, B_1(n)$ partition the set $S_1$ of $n!$ possible hidden vectors.
	
	The above computation tells us the \textit{initial} size of each bucket, which is independent of the initial query $Q_1$. Now consider the evolution of bucket sizes, \textit{i.e.,} the sequence $|B_1(s)|, |B_2(s)|, |B_3(s)|, \ldots$ over the course of an instance of the Permutation Game. We claim that this is a non-increasing sequence. Since $|B_1(s)|$ is independent of $Q_1$, assume that $Q_1 = Q_t$. Then the query $Q_t$, together with response $\Delta(Q_t, H)$, produces a bucket $B_t(s)$ defined by $B_1(s)\intersect S_t$. Since $|S_1|, |S_2|, |S_3|, \ldots$ is clearly a non-increasing sequence, it must be the case that $|B_{t}(s)| = |B_{1}(s)\intersect S_{t}|\ge |B_{1}(s)\intersect S_{t+1}| = |B_{t+1}(s)|$. Hence bucket sizes are bounded above by their initial size, \textit{i.e.,}
	\begin{equation*}
		|B_t(s)|\le |B_1(s)| = \binom{n}{s}D(n-s).
	\end{equation*}

	\subsubsection{Improved Lower Bound for the Permutation Game}
	We now employ the notion of a bucket to improve the trivial lower bound for $f(n, n)$ in the context of the Permutation Game.
	\begin{enumerate}[label=]
		\item\textbf{Theorem 2.} Consider the Permutation Game defined by $n = k$ and $R = F$. Let $\Delta = b$ (black-peg-only distance function) and let $A$ be fixed. Then for all sufficiently large $n$, we have
		\begin{equation*}
			f(n, k = n, \Delta = b, R = F, A) \ge n - \log\log(n).
		\end{equation*}
	\end{enumerate}
	\begin{proof}
		 Let $n$ be fixed. We give a proof which analyzes the evolution of $L(t)$, which we define to be a lower bound on $|S_t|$. We recall that $S_t$ is the minimal set of sequences guaranteed to contain $H$ given the responses $\Delta(Q_1, H), \Delta(Q_2, H), \ldots, \Delta(Q_{t-1}, H)$. We compute this lower bound by using a hypothetical set of queries $\{Q_1, Q_2, \ldots, Q_{t-1}\}$, constructed such that $Q_i$ maximizes the difference $|S_{i}| - |S_{i-1}|$. That is, each $Q_i$ guarantees to ``rule out'' the maximal number possibilities for $H$ in the $i\nth$ turn. The least rapidly decreasing sequence $|S_1|, |S_2|, |S_3|, \ldots$ for this set of queries will converge to $|S_i| = |S_{i+1}| = 1$, and the turn in which this convergence is initially reached will provide a lower bound for $f(n, n)$. Our approach is to find a number $r$ such that that $t\ge r$ implies $L(t) = 1$. We proceed by induction on $t$.
		 
		 Consider the $t\nth$ turn in an instance of the Permutation Game. In the terminology of buckets, the codebreaker constructs the set $S_t$ in turn $t$ by setting $S_t = B_{t-1}(\Delta(Q_{t-1}, H))$. To choose an ``optimal'' query sequence $Q_t$ (in the sense described above, which maximizes $|S_{t+1}| - |S_{t}|$), the codebreaker therefore must choose a sequence $Q_t$ which minimizes
		 \begin{equation*}
			\max_{s\in\{1,2,\ldots,n\}}|B_{t+1}(s)|.
		 \end{equation*}
		 Equivalently, the codebreaker chooses $Q_t$ such that the size of the largest bucket is as small as possible. By the discussion in Section (2.1.2), we know that $|B_t(s)|\le\binom{n}{s}D(n-s)$. The optimal query $Q_t$ will partition $S_t$ into buckets as evenly as possible, and some buckets will have size equal to their upper bound, while others will be partially filled. This best-possible partition will partition $S_t$ into two sets $X$ and $Y$ of buckets, such that $A\in X$ implies bucket $A$ is incompletely filled, $B\in Y$ implies bucket $B$ is completely filled, and $A\in X$, $B\in Y$ implies that the upper bound on $|A|$ is greater than the upper bound on $|B|$. Let $x = |X|$, so that $x$ is the number of incompletely filled buckets.
		 
		 We now give a recurrence which bounds $L(t)$. At the beginning of the $t$-th turn, we have at least $L(t-1)$ possible solutions remaining, so $|S_t|\ge L(t-1)$. Suppose that the codebreaker has selected the optimal query vector $Q_t$ for submission in turn $t$. We then have 
		\begin{align}
			L(t-1)
			& \le \sum_{i = 0}^{n}|B_i(t)|\nonumber\\
			& = \sum_{i=0}^{x-1}|B_i(t)| + \sum_{i=x}^{n}|B_i(t)|\nonumber\\
			& \le \sum_{i = 0}^{x-1}L(t) + \sum_{i=x}^{n}\binom{n}{i}D(n-i)\quad
			\text{for optimal $x$}\nonumber\\
			& = x\cdot L(t) + \sum_{i = x}^{n}\binom{n}{i}D(n-i).
		\end{align}
		Once we know $L(t)$, picking $x$ too large results in some of the smaller buckets being sub-optimally underfilled. Picking $x$ too small results in some of the larger buckets being overfilled. So adjustment of $x$ about its optimal value always increases the value of equation (2). Thus we have
		\begin{align*}
			L(t-1) & \le x\cdot L(t) + \sum_{i=x}^n\binom{n}{i}D(n-i)\quad\forall x
		\end{align*}
		Where $t$ is the number of turns taken, $L(t)$ is a lower bound on $|S_{t+1}|$ (the number of possible solutions remaining after the $t$-th turn), and $D$ is the derangements function.
		
		We now prove the following lemma.
		\begin{enumerate}[label=]
			\item\textit{Lemma 1.}
			\begin{equation*}
				\sum_{i=x}^n\binom{n}{i}D(n-i) \le \frac{n!}{x!}
			\end{equation*}
			\begin{proof}
				A combinatorial argument can be made as follows: The LHS	 denotes the number of permutations of an $n$-element vector which have	 at least $x$ fixed points. Suppose we choose $x$ fixed points and simply permute the rest of the vector. This gives $\binom{n}{x}(n-x)!=\frac{n!}{x!}$ possible permutations. Clearly this includes all vectors with at least $x$ fixed points (and over-counts by some margin), so the inequality holds.
				
				One may also observe
				\begin{align*}
					\sum_{i=x}^n\binom{n}{i}D(n-i) & =
					\frac{n!}{x!}\sum_{i=x}^{n}\frac{x!}{i!(n-i)!}D(n-i)\\
					& \qquad\text{we use the fact that }\frac{x!}{i!}\le\frac{1}{(i-x)!}\\
					& \le \frac{n!}{x!}\sum_{i=x}^{n}\frac{1}{(i-x)!(n-i)!}D(n-i)\\
					& \qquad\text{let $k=i-x$}\\
					& = \frac{n!}{x!}\sum_{k=0}^{n-x}\frac{1}{k!(n-x-k)!}D(n-x-k)\\
					& = \frac{n!}{x!(n-x)!}\sum_{k=0}^{n-x}\binom{n-x}{k}D(n-x-k)\\
					& = \frac{n!}{x!(n-x)!}(n-x)!\\
					& = \frac{n!}{x!}.
				\end{align*}
			\end{proof}
		\end{enumerate}
		
		Using Lemma 1, we have
		\begin{equation*}
			L(t-1) \le x\cdot L(t) + \frac{n!}{x!},
		\end{equation*}
		which gives
		\begin{equation*}
			L(t)\ge \frac{1}{x}\left(L(t-1)-\frac{n!}{x!}\right).
		\end{equation*}
		
		The following lemma will also be of use.
		\begin{enumerate}[label=]
			\item\textit{Lemma 2.} We recall that $n$ is fixed in defining $L(t)$. For any constant $C_n$, we have
			\begin{equation*}
				\frac{L(t)}{n!}\ge \frac{C_{n}! - (H_{C_{n}+t} - H_{C_{n}})}{(C_n+t)!}
			\end{equation*}
			where $0\le t\le n-C_{n}$ and $H_n=\sum_{i = 1}^n\frac{1}{i}$ is the $n\nth$ harmonic number.
		\begin{proof}
			While this equation holds for all $x$, to achieve a desirable bound, we will
		let $x=t+C_{n}$ for any positive constant $C_{n}$. We have
		\begin{enumerate}[label=]
		\item\textit{Base Case.} When $t=0$, we have $S_n(0)= n!$ and
			\begin{equation*}
			\frac{L(0)}{n!}\ge \frac{C_{n}! - (H_{C_{n}}-H_{C_{n}})}{C_{n}!} = 1
			\end{equation*}
			
		\item \textit{Inductive Step.} Assume the induction hypothesis holds for $t-1$.
			\begin{align*}
			\frac{L(t)}{n!}
			& \ge \frac{1}{x}\left(\frac{L(t-1)}{n!}-\frac{1}{x!}\right)
			\end{align*}
		Let $x=C_{n}+t$.
			\begin{align*}
			\frac{L(t)}{n!}
			& \ge \frac{1}{C_{n}+t}\left(\frac{L(t-1)}{n!}
			-\frac{1}{(C_{n}+t)!}\right)
			\end{align*}
		Inductively,
			\begin{align*}
			\frac{L(t)}{n!}
			& \ge \frac{1}{C_{n}+t}\left(\frac{C_{n}!-(H_{C_{n}+t} - H_{C_{n}})}
			{(C_{n}+t-1)!} - \frac{1}{(C_{n}+t)!}\right)\\
			& \ge \left(\frac{C_{n}! - (H_{C_{n}+t-1} - H_{C_{n}}) - \frac{1}{C_{n}+t}}
			{(C_{n}+t)!}\right)\\
			& \ge \left(\frac{C_{n}! - (H_{C_{n}+t} - H_{C_{n}})}{(C_{n}+t)!}\right)
			\end{align*}
			Then
			\begin{align*}
			L(n-C_{n}) & \ge n!\left(\frac{C_{n}! - (H_n - H_{C_{n}})}{n!}\right)\\
			& \ge C_{n}! - (H_n-H_{C_{n}})
			\end{align*}
		Thus the inequality holds for all $n$.
		\end{enumerate}
		\end{proof}
	\end{enumerate}
	We choose $C_{n}$ by the following reasoning: we want to achieve a lower bound
		of $n-C_{n}$ turns. Thus, we want
		\begin{equation*}
			C_{n}! - (H_n - H_{C_{n}}) > 1.
		\end{equation*}
		When $C_{n}=\log\log n$, we have $C_{n}! - (H_n - H_{C_{n}}) > 1$ for $n\ge e^{198}$, and when $C_{n}=\log n$, this is true for $n\ge 10$.
		
 	In conclusion, when $n$ is sufficiently large, the minimum number of remaining
	possible solutions after $n - \log\log n$ guesses is at least
		\begin{align*}
		L(n-\log\log n)
		& \ge (\log\log n)! - (H_n - H_{\log\log n})\\
		& > 1
		\end{align*}
	Thus there is no strategy that can identify any hidden sequence in $n-\log\log(n)$ turns or fewer. Therefore, in the Permutation Game variant of Mastermind, we have $f(n, n)\ge n - \log\log(n)$ for all sufficiently large $n$.
	\end{proof}

\subsection{Best Guesses and the Minimax Algorithm}
We now move on to an analysis of the best possible queries and the Minimax algorithm. Here, we adopt Donald Knuth's definition of a ``best possible'' query in the context of Minimax\cite{DK76}: a query sequence $Q_t$ is the \textit{best possible query} if the maximum number of solutions remaining over all responses is minimized. This is the guess chosen by the minimax algorithm.

We prove the following theorem.
\begin{enumerate}[label=]
	\item\textbf{Theorem 1.} Let $A=T$, let $\Delta$ be the black-peg-only distance function, and let $n$, $k$, and $R$ be fixed. Given a set $S_{t}$ of sequences which is known to contain $H$, there exists a query whose feedback $\Delta(Q_t, H)$ produces a smaller set $S_{t+1}$ such that $H\in S_{t+1}$ and $|S_{t+1}|\le (1-1/(nk))|S|$.	
\end{enumerate}
\begin{proof}
	We will again use the bucket terminology, and we add the notion of a \textit{sub-bucket}. A sub-bucket $D_i(j, B_t(s))\subseteq B_t(s)$ (indicating $j$ in position $i$) is defined to be the set of sequences $X = (x_1, x_2, \ldots, x_n)$ in $B_t(s)$ such that $x_i = j$. That is,
	\begin{equation*}
		D_i(j, B_t(s)) = \left\{(x_1, x_2, \ldots, x_n)\in B_t(s)\mid x_i = j\right\},
	\end{equation*}
	defined for all $i\in\mathcal{A}$.

	We proceed by induction on $n$.
	
	\textit{Base Case.} When $n=1$, we have a single-element vector. So there are at most $k$ possible solutions remaining at any step, thus $|S_t|\le k$. If we guess one of the remaining solutions $X\in S_t$, this will eliminate $1$ solution ($X$ itself) if the response is $0$, and will eliminate $|S_t|-1$ solutions if the response is $1$. So we're guaranteed to eliminate at least $1/|S_t|\ge 1/(nk)$ solutions.
		
	\textit{Inductive Step.} Assume that for $n-1$ spots and any number of colors $\widehat{k}$ (where $n\ge 2$), we are guaranteed that there is a guess that eliminates a fraction at least $1/(n\widehat{k})$ of the solutions.
		
	Consider a guess vector $\sigma=\{\sigma_1, \sigma_2, \ldots, \sigma_n\}$. We will analyze the number of solutions eliminated from $S_t$ by guessing $\sigma$ in the worst-case. We partition $S_t$ into $n$ buckets $B_t(1), B_t(2), \ldots, B_t(n)$. Consider the response $j$ that eliminates as few possible solutions as possible from $S$, so $|B_t(j)| = \max\{|B_t(1)|, |B_t(2)|, \ldots, |B_t(n)|\}$.
	% TODO: copy over inductive step with new notation.
	
	
\end{proof}

\clearpage
\bibliographystyle{acm}
\bibliography{QCMV_Bibliography.bib}

\end{document}

























